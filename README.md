# Explainable Anomaly Detection with DIFFI and SHAP
This is the codebase for the research paper by Justin Snelders for the Radboud University course Explainable AI. 
The project investigates the use of DIFFI and SHAP to explain anomaly detection results from an Isolation Forest model trained on bank transaction data.

### Research Question

How can post-hoc explanation methods such as SHAP and DIFFI enhance the interpretability of Isolation Forest models in the context of bank transaction fraud detection?

# Installation
The installation procedure for this project is straightforward:
1. Fork this repository and navigate to the local directory
2. Install the required dependencies using `pip install -r requirements.txt`
3. Follow the steps in the Jupyter Notebook

The Jupyter Notebook contains the code and written instructions and descriptions for each stage of the analysis.
